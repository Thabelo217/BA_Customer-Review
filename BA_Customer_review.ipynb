{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCRAPING DATA FROM SKYTRAX**\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use Python and BeautifulSoup to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  This recent long-haul experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |   Check-in was slow with onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Check in was smooth enough. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | Although transferring to thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   We are extremely grateful ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified |  This recent long-haul experien...\n",
       "1  ✅ Trip Verified |   Check-in was slow with onl...\n",
       "2  Not Verified |  Check in was smooth enough. Bo...\n",
       "3  ✅ Trip Verified | Although transferring to thi...\n",
       "4  ✅ Trip Verified |   We are extremely grateful ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create 'data' folder if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Then save the file\n",
    "df.to_csv(\"data/BA_reviews.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  This recent long-haul experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |   Check-in was slow with onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Check in was smooth enough. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | Although transferring to thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |   We are extremely grateful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Not Verified |  I did not actually fly because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>✅ Trip Verified | The start of our journey bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Not Verified | Chicago to Zurich via London. D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>✅ Trip Verified | Glasgow to London. Smooth fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>✅ Trip Verified | Having booked this flight a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    Not Verified |  This recent long-haul experien...\n",
       "1    ✅ Trip Verified |   Check-in was slow with onl...\n",
       "2    Not Verified |  Check in was smooth enough. Bo...\n",
       "3    ✅ Trip Verified | Although transferring to thi...\n",
       "4    ✅ Trip Verified |   We are extremely grateful ...\n",
       "..                                                 ...\n",
       "995  Not Verified |  I did not actually fly because...\n",
       "996  ✅ Trip Verified | The start of our journey bac...\n",
       "997  Not Verified | Chicago to Zurich via London. D...\n",
       "998  ✅ Trip Verified | Glasgow to London. Smooth fl...\n",
       "999  ✅ Trip Verified | Having booked this flight a ...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  \\\n",
      "0  Not Verified |  This recent long-haul experien...   \n",
      "1  ✅ Trip Verified |   Check-in was slow with onl...   \n",
      "2  Not Verified |  Check in was smooth enough. Bo...   \n",
      "3  ✅ Trip Verified | Although transferring to thi...   \n",
      "4  ✅ Trip Verified |   We are extremely grateful ...   \n",
      "\n",
      "                                      Cleaned_Review  \n",
      "0  verified recent longhaul experience disappoint...  \n",
      "1  checkin slow one staff member checking economy...  \n",
      "2  verified check smooth enough boarding chaotic ...  \n",
      "3  although transferring flight heathrow budapest...  \n",
      "4  extremely grateful crew flight ba0058 cape tow...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thabe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords (first time only)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_review(text):\n",
    "    # Remove \"✅ Trip Verified\" and similar tokens\n",
    "    text = re.sub(r'✅\\s*Trip Verified', '', text)\n",
    "    \n",
    "    # Remove punctuation and non-alphanumeric characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning\n",
    "df['Cleaned_Review'] = df['reviews'].apply(clean_review)\n",
    "\n",
    "# Preview cleaned text\n",
    "print(df[['reviews', 'Cleaned_Review']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['Cleaned_Review'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                  1000\n",
       "unique                                                 1000\n",
       "top       verified recent longhaul experience disappoint...\n",
       "freq                                                      1\n",
       "Name: Cleaned_Review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    verified recent longhaul experience disappoint...\n",
       "1    checkin slow one staff member checking economy...\n",
       "2    verified check smooth enough boarding chaotic ...\n",
       "3    although transferring flight heathrow budapest...\n",
       "4    extremely grateful crew flight ba0058 cape tow...\n",
       "Name: Cleaned_Review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      verified recent longhaul experience disappoint...\n",
       "1      checkin slow one staff member checking economy...\n",
       "2      verified check smooth enough boarding chaotic ...\n",
       "3      although transferring flight heathrow budapest...\n",
       "4      extremely grateful crew flight ba0058 cape tow...\n",
       "                             ...                        \n",
       "995    verified actually fly pilot strike review poor...\n",
       "996    start journey back efl inauspicious hundreds d...\n",
       "997    verified chicago zurich via london delays dela...\n",
       "998    glasgow london smooth flight departurearrival ...\n",
       "999    booked flight week ba strike mistakingly think...\n",
       "Name: Cleaned_Review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performs sentiment classification using TextBlob and a Logistic Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    polarity = TextBlob(text).sentiment.polarity\n",
    "    if polarity > 0:\n",
    "        return 'positive'\n",
    "    elif polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['Sentiment'] = df['Cleaned_Review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      negative\n",
       "1      negative\n",
       "2      positive\n",
       "3      positive\n",
       "4      positive\n",
       "         ...   \n",
       "995    positive\n",
       "996    positive\n",
       "997    positive\n",
       "998    positive\n",
       "999    positive\n",
       "Name: Sentiment, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='Sentiment', data=df, order=['positive', 'neutral', 'negative'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.46      0.55        68\n",
      "     neutral       0.00      0.00      0.00         3\n",
      "    positive       0.76      0.91      0.83       129\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.48      0.46      0.46       200\n",
      "weighted avg       0.73      0.74      0.72       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define features (X) and target labels (y)\n",
    "X = df['Cleaned_Review']  # Text data\n",
    "y = df['Sentiment']       # Sentiment labels\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a simple classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
